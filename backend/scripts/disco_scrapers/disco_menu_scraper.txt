# dia_menu_scraper.py
# Requiere: selenium, pandas, webdriver_manager, pymongo
# > pip install selenium pandas webdriver-manager pymongo

from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.chrome.service import Service
from webdriver_manager.chrome import ChromeDriverManager
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.webdriver.common.action_chains import ActionChains
from pymongo import MongoClient
from datetime import datetime, timezone
import time
import unicodedata
import re
import os

HOME_URL = "https://diaonline.supermercadosdia.com.ar/"

def setup_driver(headless: bool = True):
    opts = Options()
    if headless:
        opts.add_argument("--headless")
    opts.add_argument("--window-size=1920,1080")
    opts.add_argument("--disable-blink-features=AutomationControlled")
    opts.add_experimental_option("excludeSwitches", ["enable-automation"])
    opts.add_experimental_option("useAutomationExtension", False)
    opts.add_argument("--user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36")
    opts.add_argument("--remote-debugging-port=9222")
    return webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=opts)

def wait_for_page_load(driver, wait):
    print("üîÑ Esperando que cargue la p√°gina...")
    try:
        wait.until(EC.presence_of_element_located((By.TAG_NAME, "body")))
        time.sleep(5)
        print("‚úÖ P√°gina cargada")
        return True
    except Exception as e:
        print(f"‚ùå Error esperando carga: {e}")
        return False

def deploy_categories_menu(driver, wait):
    print("üîÑ Desplegando men√∫ de categor√≠as...")
    try:
        categories_button = wait.until(
            EC.element_to_be_clickable((By.CSS_SELECTOR,
                "div.diaio-custom-mega-menu-0-x-custom-mega-menu-trigger__button"
            ))
        )
        categories_button.click()
        time.sleep(2)
        print("‚úÖ Click realizado sobre 'Categor√≠as'")
        return True
    except Exception as e:
        print(f"‚ùå Error desplegando men√∫: {e}")
        return False

def get_all_category_links(driver, wait):
    print("üîÑ Obteniendo enlaces de todas las categor√≠as...")
    try:
        category_selectors = [
            "div.diaio-custom-mega-menu-0-x-category-list__container a.diaio-custom-mega-menu-0-x-category-list-item__container"
        ]
        category_links = []
        for selector in category_selectors:
            try:
                elements = driver.find_elements(By.CSS_SELECTOR, selector)
                for element in elements:
                    if element.is_displayed():
                        href = element.get_attribute('href')
                        text = element.text.strip()
                        if href and text and 'diaonline.supermercadosdia.com.ar' in href:
                            if not any(link['href'] == href for link in category_links):
                                category_links.append({
                                    'name': text,
                                    'href': href,
                                    'element': element
                                })
                if category_links:
                    print(f"‚úÖ Encontrados {len(category_links)} enlaces con: {selector}")
                    break
            except Exception as e:
                print(f"‚ö†Ô∏è  Selector {selector} fall√≥: {e}")
        return category_links
    except Exception as e:
        print(f"‚ùå Error obteniendo enlaces: {e}")
        return []

def find_filter_container(driver):
    selectors = [
        "div.diaio-search-result-0-x-filter__container"
    ]
    for selector in selectors:
        try:
            elements = driver.find_elements(By.CSS_SELECTOR, selector)
            if elements:
                print(f"‚úÖ Contenedor encontrado con: {selector}")
                return elements[0]
        except Exception as e:
            print(f"‚ö†Ô∏è  Selector {selector} fall√≥: {e}")
    print("‚ùå No se encontr√≥ el contenedor de filtros")
    return None


def get_all_group_titles(container):
    selectors = [
        "div[class*='filterTitle']"  # T√≠tulos de grupo de filtros
    ]
    for selector in selectors:
        try:
            groups = container.find_elements(By.CSS_SELECTOR, selector)
            return [g.text.strip() for g in groups if g.text.strip()]
        except:
            continue
    return []

def process_single_group(container, driver, group_name, group_index):
    try:
        # Buscar el t√≠tulo del grupo por texto
        group_elements = container.find_elements(By.XPATH, f".//div[contains(@class, 'filterTitle') and contains(text(), '{group_name}')]")
        if not group_elements:
            return []
        group_element = group_elements[0]
        driver.execute_script("arguments[0].scrollIntoView({block: 'center'});", group_element)
        time.sleep(1)

        # Contenedor padre del grupo
        parent_container = group_element.find_element(By.XPATH, "./ancestor::div[contains(@class, 'filterTemplateOverflow')]")

        # Selector de opciones individuales
        option_selectors = [
            "div[class*='filterItem']"  # √çtems dentro del grupo
        ]
        options = []
        for opt_selector in option_selectors:
            try:
                items = parent_container.find_elements(By.CSS_SELECTOR, opt_selector)
                for item in items:
                    try:
                        label_raw = item.find_element(By.CSS_SELECTOR, "label").text.strip()
                        if label_raw:
                            options.append(label_raw)
                    except:
                        continue
            except:
                continue
        return options
    except:
        return []

def scrape_all_groups_sequentially(container, driver):
    scroll_container_to_reveal_groups(container, driver)
    group_names = get_all_group_titles(container)
    all_data = {}
    for i, group_name in enumerate(group_names):
        options = process_single_group(container, driver, group_name, i)
        if options:
            all_data[group_name] = options
        time.sleep(1)
    return all_data

def normalize_name(name: str) -> str:
    name = unicodedata.normalize('NFKD', name).encode('ASCII', 'ignore').decode('utf-8')
    name = re.sub(r'\W+', '_', name).lower()
    return name.strip('_')

def normalize_grupo(grupo):
    g = unicodedata.normalize('NFKD', grupo).encode('ASCII', 'ignore').decode().lower().strip()
    if g.endswith('s') and not g.endswith('es'):
        g = g[:-1]
    return g

def normalize_text(text):
    return unicodedata.normalize('NFKD', text).encode('ASCII', 'ignore').decode().lower().strip()

def normalize_opciones(opciones):
    return sorted(list(set([normalize_text(o) for o in opciones if o])))

def store_categories_in_mongo(data: dict, category_name: str):
    client = MongoClient("mongodb://localhost:27017/")
    db = client["supermercados_raw_dia"]
    collection = db["categorias_raw"]
    normalized_name = normalize_name(category_name)
    filters_array = [{"group": k, "options": v} for k, v in data.items()]
    document = {
        "category": category_name,
        "normalized": normalized_name,
        "timestamp": datetime.now(timezone.utc),
        "filters": filters_array
    }
    collection.replace_one({"normalized": normalized_name}, document, upsert=True)

def store_filters_in_mongo(data: dict, category_name: str):
    client = MongoClient("mongodb://localhost:27017/")
    db = client["supermercados_raw_dia"]
    collection = db["filtros_raw"]
    normalized_name = normalize_name(category_name)

    for group_name, options in data.items():
        document = {
            "category": category_name,
            "normalized": normalized_name,
            "group": group_name,
            "options": options,
            "timestamp": datetime.now(timezone.utc)
        }
        collection.replace_one(
            {"normalized": normalized_name, "group": group_name},
            document,
            upsert=True
        )

def normalize_and_store(data: dict, category_name: str):
    try:
        client = MongoClient("mongodb://localhost:27017/")
        db = client["supermercados_normalized_dia"]
        collection = db["filtros"]
        normalized_name = normalize_name(category_name)
        timestamp = datetime.now()

        for group_name, opciones in data.items():
            doc = {
                "supermercado": "dia",
                "categoria_original": category_name,
                "categoria_normalizada": normalized_name,
                "grupo": group_name,
                "grupo_normalizado": normalize_grupo(group_name),
                "opciones": normalize_opciones(opciones),
                "timestamp": timestamp
            }
            collection.insert_one(doc)
        print(f"üßº Normalized data guardada para categor√≠a: {category_name}")

    except Exception as e:
        print(f"‚ùå Error guardando normalized data: {e}")

def store_metadata(data: dict, category_name: str, version_scraper: str = "dia_scraper_v1.0"):
    try:
        client = MongoClient("mongodb://localhost:27017/")
        db = client["supermercados_metadata_dia"]
        collection = db["categorias_metadata"]
        normalized_name = normalize_name(category_name)
        timestamp = datetime.now()

        grupos = []
        total_opciones = 0
        for group_name, opciones in data.items():
            grupo_norm = normalize_grupo(group_name)
            cantidad = len(opciones)
            total_opciones += cantidad
            grupos.append({
                "grupo_original": group_name,
                "grupo_normalizado": grupo_norm,
                "cantidad_opciones": cantidad
            })

        doc = {
            "supermercado": "dia",
            "categoria_original": category_name,
            "categoria_normalizada": normalized_name,
            "timestamp": timestamp,
            "grupos_detectados": len(data),
            "total_opciones": total_opciones,
            "grupos": grupos,
            "status": "success",
            "version_scraper": version_scraper,
            "errores": []
        }

        collection.insert_one(doc)
        print(f"üìù Metadata guardada para categor√≠a: {category_name}")

    except Exception as e:
        print(f"‚ùå Error guardando metadata: {e}")

def scrape_category_filters(driver, wait, category_url, category_name):
    print(f"üîÑ Scrapeando filtros de: {category_name}")
    try:
        driver.get(category_url)
        if not wait_for_page_load(driver, wait):
            print(f"‚ùå No se pudo cargar la p√°gina de {category_name}")
            return False
        container = find_filter_container(driver)
        if not container:
            print(f"‚ùå No se encontr√≥ contenedor de filtros en {category_name}")
            return False
        filtros = scrape_all_groups_sequentially(container, driver)
        if filtros:
            store_categories_in_mongo(filtros, category_name)
            store_filters_in_mongo(filtros, category_name)
            normalize_and_store(filtros, category_name)
            store_metadata(filtros, category_name)
            return True
        else:
            print(f"‚ö†Ô∏è  No se extrajeron datos de {category_name}")
            return False
    except Exception as e:
        print(f"‚ùå Error scrapeando {category_name}: {e}")
        return False

def main():
    print("üöÄ Iniciando scraper de Dia...")

    base_dir = os.path.join(os.environ["USERPROFILE"], "AppData", "Local", "Temp", "dia_profiles")
    os.makedirs(base_dir, exist_ok=True)

    driver = setup_driver(headless=False)
    wait = WebDriverWait(driver, 30)

    try:
        print(f"üåê Navegando al home: {HOME_URL}")
        driver.get(HOME_URL)

        if not wait_for_page_load(driver, wait):
            print("‚ùå La p√°gina home no carg√≥ correctamente")
            return

        if not deploy_categories_menu(driver, wait):
            print("‚ùå No se pudo desplegar el men√∫ de categor√≠as")
            return

        category_links = get_all_category_links(driver, wait)
        if not category_links:
            print("‚ùå No se encontraron enlaces de categor√≠as")
            return

        print(f"üéØ Procesando {len(category_links)} categor√≠as...")

        successful_categories = 0
        for i, category in enumerate(category_links, 1):
            print(f"\n{'='*60}")
            print(f"üìÇ Procesando categor√≠a {i}/{len(category_links)}: {category['name']}")
            print(f"üîó URL: {category['href']}")
            print(f"{'='*60}")

            if scrape_category_filters(driver, wait, category['href'], category['name']):
                successful_categories += 1
                print(f"‚úÖ Categor√≠a {category['name']} procesada exitosamente")
            else:
                print(f"‚ùå Error procesando categor√≠a {category['name']}")

            if i < len(category_links):
                print("üîÑ Volviendo al home para la siguiente categor√≠a...")
                driver.get(HOME_URL)
                if wait_for_page_load(driver, wait):
                    if not deploy_categories_menu(driver, wait):
                        print("‚ö†Ô∏è  Error desplegando men√∫ para siguiente categor√≠a")
                        break
                else:
                    print("‚ö†Ô∏è  Error cargando home para siguiente categor√≠a")
                    break

        print(f"\nüéâ ¬°Proceso completado!")
        print(f"üìä Categor√≠as procesadas exitosamente: {successful_categories}/{len(category_links)}")

    except Exception as e:
        print(f"‚ùå Error general: {e}")

    finally:
        print("üõë Scraping finalizado. Presiona Enter para cerrar el navegador...")
        input()
        driver.quit()

if __name__ == "__main__":
    main()